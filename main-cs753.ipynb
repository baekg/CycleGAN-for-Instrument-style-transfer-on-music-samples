{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (2, 256, 128, 1) (2, 256, 128, 1)\n",
      "image_shape (256, 128, 1)\n",
      "(None, 8, 4, 1)\n",
      ">1, dA[0.419,0.007] dB[0.364,0.002] g[6.155,6.513]\n",
      ">Saved: g_model_AtoB.h5 and g_model_BtoA.h5\n",
      ">2, dA[0.324,0.006] dB[0.255,0.014] g[6.733,6.777]\n",
      ">Saved: g_model_AtoB.h5 and g_model_BtoA.h5\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# define the discriminator model\n",
    "def define_discriminator(shape):\n",
    "    # weight initialization\n",
    "    padding=\"same\"\n",
    "    stride=(2,2)\n",
    "    depth=[128,256,512,512]\n",
    "    alpha=0.3\n",
    "    filter_size=(4,1)\n",
    "    strides=(2,2)\t\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "\n",
    "    x=tf.keras.Input(shape=shape)\n",
    "    d = tf.keras.layers.Conv2D(64, filter_size, strides=strides, padding='same',kernel_initializer=init)(x)\n",
    "    d = tf.keras.layers.LeakyReLU(alpha=0.2)(d)\n",
    "    for i in depth:\n",
    "        d = tf.keras.layers.Conv2D(i, filter_size, strides=strides, padding='same',kernel_initializer=init)(d)\n",
    "        d = tf.keras.layers.BatchNormalization()(d)\n",
    "        d = tf.keras.layers.LeakyReLU(alpha=0.2)(d)  \n",
    "        d = tf.keras.layers.Conv2D(1,filter_size, padding='same',kernel_initializer=init)(d)\n",
    "    # define model\n",
    "    model = tf.keras.Model(x, d)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5),loss_weights=[0.5])\n",
    "    return model\n",
    "\n",
    "def define_generator(shape):\n",
    "    depth=[128,256,512]\n",
    "    f_shape1=(7,7)\n",
    "    f_shape2=(3,3)\n",
    "    stride1=(2,1)\n",
    "    dil1=(1,1)   \n",
    "    padding=\"same\"\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    n_resnet=3 # orginally 3\n",
    "    x=tf.keras.Input(shape=shape)\n",
    "    g = tf.keras.layers.Conv2D(64, f_shape1, padding=padding,kernel_initializer=init)(x)\n",
    "    g = tf.keras.layers.BatchNormalization()(g)\n",
    "    g = tf.keras.layers.LeakyReLU()(g)\n",
    "    for i in depth:\n",
    "        g = tf.keras.layers.Conv2D(i, f_shape2, padding=padding,strides=stride1,kernel_initializer=init)(g)\n",
    "        g = tf.keras.layers.BatchNormalization()(g)\n",
    "        g = tf.keras.layers.LeakyReLU()(g)\n",
    "    # R256\n",
    "    for _ in range(n_resnet):\n",
    "        y=g\n",
    "        g = tf.keras.layers.Conv2D(depth[-1], f_shape2, padding=padding,kernel_initializer=init)(g)\n",
    "        g = tf.keras.layers.BatchNormalization()(g)\n",
    "        g = tf.keras.layers.LeakyReLU()(g)\n",
    "        g = tf.keras.layers.Conv2D(depth[-1], f_shape2, padding=padding,kernel_initializer=init)(g)\n",
    "        g = tf.keras.layers.BatchNormalization()(g)\n",
    "        g=tf.keras.layers.Concatenate()([g,y])\n",
    "    # u128\n",
    "    depth.reverse()\n",
    "    for i in depth:        \n",
    "        g = tf.keras.layers.Conv2DTranspose(i, f_shape2, padding=padding,strides=stride1,kernel_initializer=init)(g)\n",
    "        g = tf.keras.layers.BatchNormalization()(g)\n",
    "        g = tf.keras.layers.LeakyReLU()(g)\n",
    "\n",
    "    g = tf.keras.layers.Conv2DTranspose(1, f_shape1, padding=padding,kernel_initializer=init)(g)\n",
    "    g = tf.keras.layers.BatchNormalization()(g)\n",
    "    g = tf.keras.activations.tanh(g)\n",
    "    # define model\n",
    "    model = tf.keras.Model(x,g)\n",
    "    return model\n",
    "\n",
    "\n",
    "    # define a composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    # ensure the model we're updating is trainable\n",
    "    g_model_1.trainable = True\n",
    "    # mark discriminator as not trainable\n",
    "    d_model.trainable = False\n",
    "    # mark other generator model as not trainable\n",
    "    g_model_2.trainable = False\n",
    "    # discriminator element\n",
    "    input_gen = tf.keras.Input(shape=image_shape)\n",
    "    gen1_out = g_model_1(input_gen)\n",
    "    output_d = d_model(gen1_out)\n",
    "    # identity element\n",
    "    input_id = tf.keras.Input(shape=image_shape)\n",
    "    output_id = g_model_1(input_id)\n",
    "    # forward cycle\n",
    "    output_f = g_model_2(gen1_out)\n",
    "    # backward cycle\n",
    "    gen2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen2_out)\n",
    "    # define model graph\n",
    "    model = tf.keras.models.Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    # define optimization algorithm configuration\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "    # compile model with weighting of least squares loss and L1 loss\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
    "    return model\n",
    "\n",
    " \n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape0,patch_shape1):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, patch_shape0, patch_shape1, 1))\n",
    "    return X, y\n",
    " \n",
    "    # generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset,patch_shape0,patch_shape1):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(dataset)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((len(X), patch_shape0, patch_shape1, 1))\n",
    "    return X, y\n",
    "\n",
    "    # save the generator models to file\n",
    "def save_models(step, g_model_AtoB, g_model_BtoA,dA,dB):\n",
    "    # save the first generator model\n",
    "    filename1 = 'g_model_AtoB.h5'\n",
    "    g_model_AtoB.save(filename1)\n",
    "    # save the second generator model\n",
    "    filename2 = 'g_model_BtoA.h5' \n",
    "    g_model_BtoA.save(filename2)\n",
    "    dA.save('d_model_A.h5')\n",
    "    dB.save('d_model_B.h5')\n",
    "\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))\n",
    " \n",
    "    # generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
    "    # select a sample of input images\n",
    "    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
    "    # generate translated images\n",
    "    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_in = (X_in + 1) / 2.0\n",
    "    X_out = (X_out + 1) / 2.0\n",
    "    # plot real images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(2, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_in[i])\n",
    "    # plot translated image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_out[i])\n",
    "    # save plot to file\n",
    "    filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    " \n",
    "# update image pool for fake images\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            # use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # replace an existing image and use replaced image\n",
    "            ix = randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return asarray(selected)\n",
    " \n",
    "# train cyclegan models\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
    "    # n_epochs, n_batch, = 100, 1 # original\n",
    "    n_epochs, n_batch, = 1, 1\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch0 = d_model_A.output_shape[1]\n",
    "    n_patch1 = d_model_A.output_shape[2]\n",
    "    print(d_model_A.output_shape)\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # prepare image pool for fakes\n",
    "    poolA, poolB = list(), list()\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "    # select a batch of real samples\n",
    "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch0,n_patch1)\n",
    "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch0,n_patch1)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch0,n_patch1)\n",
    "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch0,n_patch1)\n",
    "        # update fakes from pool\n",
    "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "        # update generator B->A via adversarial and cycle loss\n",
    "        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        # update discriminator for A -> [real/fake]\n",
    "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "        # update generator A->B via adversarial and cycle loss\n",
    "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        # update discriminator for B -> [real/fake]\n",
    "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "        # summarize performance\n",
    "        print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "        # evaluate the model performance every so often\n",
    "#         if (i+1) % (bat_per_epo * 1) == 0:\n",
    "          # plot A->B translation\n",
    "#           summarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
    "          # plot B->A translation\n",
    "#           summarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
    "        if (i+1) % 1 == 0:\n",
    "            save_models(i, g_model_AtoB, g_model_BtoA,d_model_A,d_model_B)\n",
    "\n",
    "# load image data\n",
    "dataset_A = np.load('../input/gac-pia/data_gac.npz')[\"arr_0\"][:2]\n",
    "dataset_B = np.load('../input/gac-pia/data_pia.npz')[\"arr_0\"][:2]\n",
    "dataset_A=np.expand_dims(dataset_A,axis=-1)\n",
    "dataset_B=np.expand_dims(dataset_B,axis=-1)\n",
    "dataset=np.array([dataset_A, dataset_B])\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "print(\"image_shape\", image_shape)\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "load=1\n",
    "if load==1:\n",
    "    g_model_AtoB.load_weights(\"../input/main-cs753/g_model_AtoB.h5\")\n",
    "    g_model_BtoA.load_weights(\"../input/main-cs753/g_model_BtoA.h5\")\n",
    "    d_model_A.load_weights(\"../input/main-cs753/d_model_A.h5\")\n",
    "    d_model_B.load_weights(\"../input/main-cs753/d_model_B.h5\")\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __results__.html  d_model_A.h5  g_model_AtoB.h5\r\n",
      "__output__.json     custom.css\t      d_model_B.h5  g_model_BtoA.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/main-cs753/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
